{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37164bitbaseconda69a353b5aff44ec29d8ca504b49817c4",
   "display_name": "Python 3.7.1 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = (SparkSession.builder.appName('bigquery').getOrCreate())\n",
    "\n",
    "pubg=spark.read.csv('C:/Users/faisa/OneDrive - Letterkenny Institute of Technology/2nd Semester/Big Data Analytics - Shagufta/Technical Project/PUBG/pubg_prediction/final.csv', header=True)\n",
    "\n",
    "\n",
    "pubg_y=spark.read.csv('C:/Users/faisa/OneDrive - Letterkenny Institute of Technology/2nd Semester/Big Data Analytics - Shagufta/Technical Project/PUBG/pubg_prediction/final2.csv', header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "root\n |-- assists: string (nullable = true)\n |-- boosts: string (nullable = true)\n |-- damageDealt: string (nullable = true)\n |-- DBNOs: string (nullable = true)\n |-- headshotKills: string (nullable = true)\n |-- heals: string (nullable = true)\n |-- killPlace: string (nullable = true)\n |-- killPoints: string (nullable = true)\n |-- kills: string (nullable = true)\n |-- killStreaks: string (nullable = true)\n |-- longestKill: string (nullable = true)\n |-- matchDuration: string (nullable = true)\n |-- matchType: string (nullable = true)\n |-- maxPlace: string (nullable = true)\n |-- numGroups: string (nullable = true)\n |-- rankPoints: string (nullable = true)\n |-- revives: string (nullable = true)\n |-- rideDistance: string (nullable = true)\n |-- roadKills: string (nullable = true)\n |-- swimDistance: string (nullable = true)\n |-- teamKills: string (nullable = true)\n |-- vehicleDestroys: string (nullable = true)\n |-- walkDistance: string (nullable = true)\n |-- weaponsAcquired: string (nullable = true)\n |-- winPoints: string (nullable = true)\n |-- match_mean: string (nullable = true)\n |-- match_median: string (nullable = true)\n |-- totalPlayers: string (nullable = true)\n |-- teamSize: string (nullable = true)\n |-- killsNorm: string (nullable = true)\n |-- damageDealtNorm: string (nullable = true)\n |-- normMatchType: string (nullable = true)\n |-- totalDistance: string (nullable = true)\n |-- maxPossibleKills: string (nullable = true)\n |-- itemsUsed: string (nullable = true)\n |-- itemsPerDistance: string (nullable = true)\n |-- killsPerDistance: string (nullable = true)\n |-- damageDealtPerDistance: string (nullable = true)\n |-- maxTeamKills: string (nullable = true)\n |-- totalTeamKills: string (nullable = true)\n |-- headshotKillRate: string (nullable = true)\n |-- itemsUsedPerTeam: string (nullable = true)\n |-- percKill: string (nullable = true)\n |-- percTeamKills: string (nullable = true)\n |-- meanTeamKillPlace: string (nullable = true)\n\n"
    }
   ],
   "source": [
    "pubg.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['assists', 'boosts', 'damageDealt', 'DBNOs', 'headshotKills', 'heals', 'killPlace', 'killPoints', 'kills', 'killStreaks', 'longestKill', 'matchDuration', 'matchType', 'maxPlace', 'numGroups', 'rankPoints', 'revives', 'rideDistance', 'roadKills', 'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance', 'weaponsAcquired', 'winPoints', 'match_mean', 'match_median', 'totalPlayers', 'teamSize', 'killsNorm', 'damageDealtNorm', 'normMatchType', 'totalDistance', 'maxPossibleKills', 'itemsUsed', 'itemsPerDistance', 'killsPerDistance', 'damageDealtPerDistance', 'maxTeamKills', 'totalTeamKills', 'headshotKillRate', 'itemsUsedPerTeam', 'percKill', 'percTeamKills', 'meanTeamKillPlace']\n"
    }
   ],
   "source": [
    "cols = pubg.columns\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in cols:\n",
    "    pubg = pubg.withColumn(col, pubg[col].cast(FloatType()))\n",
    "\n",
    "\n",
    "# #Creating feature vector\n",
    "# vectorAssembler = VectorAssembler(inputCols = cols, outputCol = 'features')\n",
    "\n",
    "# #Transforming the dataframe \n",
    "# pubg_df=vectorAssembler.transform(pubg)\n",
    "\n",
    "# #Selecting features and target variable from the dataframe\n",
    "# pubg_df = pubg_df.select(['features', 'winPlacePerc'])\n",
    "# pubg_df.show(3)\n",
    "\n",
    "#Splitting the data into test and train\n",
    "X_train, X_val, y_train, y_val = train_test_split(pubg.toPandas(), pubg_y.toPandas(), train_size=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['assists', 'boosts', 'damageDealt', 'DBNOs', 'headshotKills', 'heals',\n       'killPlace', 'killPoints', 'kills', 'killStreaks', 'longestKill',\n       'matchDuration', 'matchType', 'maxPlace', 'numGroups', 'rankPoints',\n       'revives', 'rideDistance', 'roadKills', 'swimDistance', 'teamKills',\n       'vehicleDestroys', 'walkDistance', 'weaponsAcquired', 'winPoints',\n       'match_mean', 'match_median', 'totalPlayers', 'teamSize', 'killsNorm',\n       'damageDealtNorm', 'normMatchType', 'totalDistance', 'maxPossibleKills',\n       'itemsUsed', 'itemsPerDistance', 'killsPerDistance',\n       'damageDealtPerDistance', 'maxTeamKills', 'totalTeamKills',\n       'headshotKillRate', 'itemsUsedPerTeam', 'percKill', 'percTeamKills',\n       'meanTeamKillPlace'],\n      dtype='object')"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(cl,name):\n",
    "  print(name)\n",
    "  print('Mean Absolute Error is {:.5f}'.format(mean_absolute_error(y_val, cl.predict(X_val))))\n",
    "  print('R2 score is {:.2%}'.format(r2_score(y_val, cl.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "linear\nMean Absolute Error is 0.00679\nR2 score is -0.13%\nridge\nMean Absolute Error is 0.01005\nR2 score is 16.19%\nlasso\nMean Absolute Error is 0.01250\nR2 score is -8.91%\nelastic\nMean Absolute Error is 0.01228\nR2 score is -8.28%\nAdaboost\nMean Absolute Error is 0.00203\nR2 score is 91.71%\nC:\\Users\\faisa\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\nC:\\Users\\faisa\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\nC:\\Users\\faisa\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:26: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\nGBR\nMean Absolute Error is 0.00114\nR2 score is 94.86%\nforest\nMean Absolute Error is 0.00127\nR2 score is 93.97%\ntree\nMean Absolute Error is 0.00202\nR2 score is 81.58%\n"
    }
   ],
   "source": [
    "linear = LinearRegression(copy_X=True)\n",
    "linear.fit(X_train,y_train)\n",
    "calculate_error(linear,\"linear\")\n",
    "\n",
    "ridge = Ridge(copy_X=True)\n",
    "ridge.fit(X_train,y_train)\n",
    "calculate_error(ridge,\"ridge\")\n",
    "\n",
    "lasso = Lasso(copy_X=True)\n",
    "lasso.fit(X_train,y_train)\n",
    "calculate_error(lasso,\"lasso\")\n",
    "\n",
    "elastic = ElasticNet(copy_X=True)\n",
    "elastic.fit(X_train,y_train)\n",
    "calculate_error(elastic,\"elastic\")\n",
    "\n",
    "ada = AdaBoostRegressor(learning_rate=0.8)\n",
    "ada.fit(X_train,y_train)\n",
    "calculate_error(ada,\"Adaboost\")\n",
    "\n",
    "GBR = GradientBoostingRegressor(learning_rate=0.8)\n",
    "GBR.fit(X_train,y_train)\n",
    "calculate_error(GBR,\"GBR\")\n",
    "\n",
    "forest = RandomForestRegressor(n_estimators=10)\n",
    "forest.fit(X_train,y_train)\n",
    "calculate_error(forest,\"forest\")\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train,y_train)\n",
    "calculate_error(tree,\"tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "'Field \"features\" does not exist.\\nAvailable fields: assists, boosts, damageDealt, DBNOs, headshotKills, heals, killPlace, killPoints, kills, killStreaks, longestKill, matchDuration, matchType, maxPlace, numGroups, rankPoints, revives, rideDistance, roadKills, swimDistance, teamKills, vehicleDestroys, walkDistance, weaponsAcquired, winPoints, match_mean, match_median, totalPlayers, teamSize, killsNorm, damageDealtNorm, normMatchType, totalDistance, maxPossibleKills, itemsUsed, itemsPerDistance, killsPerDistance, damageDealtPerDistance, maxTeamKills, totalTeamKills, headshotKillRate, itemsUsedPerTeam, percKill, percTeamKills, meanTeamKillPlace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o8094.fit.\n: java.lang.IllegalArgumentException: Field \"features\" does not exist.\nAvailable fields: assists, boosts, damageDealt, DBNOs, headshotKills, heals, killPlace, killPoints, kills, killStreaks, longestKill, matchDuration, matchType, maxPlace, numGroups, rankPoints, revives, rideDistance, roadKills, swimDistance, teamKills, vehicleDestroys, walkDistance, weaponsAcquired, winPoints, match_mean, match_median, totalPlayers, teamSize, killsNorm, damageDealtNorm, normMatchType, totalDistance, maxPossibleKills, itemsUsed, itemsPerDistance, killsPerDistance, damageDealtPerDistance, maxTeamKills, totalTeamKills, headshotKillRate, itemsUsedPerTeam, percKill, percTeamKills, meanTeamKillPlace\r\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:274)\r\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:274)\r\n\tat scala.collection.MapLike$class.getOrElse(MapLike.scala:128)\r\n\tat scala.collection.AbstractMap.getOrElse(Map.scala:59)\r\n\tat org.apache.spark.sql.types.StructType.apply(StructType.scala:273)\r\n\tat org.apache.spark.ml.util.SchemaUtils$.checkColumnType(SchemaUtils.scala:41)\r\n\tat org.apache.spark.ml.PredictorParams$class.validateAndTransformSchema(Predictor.scala:51)\r\n\tat org.apache.spark.ml.regression.DecisionTreeRegressor.org$apache$spark$ml$tree$DecisionTreeRegressorParams$$super$validateAndTransformSchema(DecisionTreeRegressor.scala:47)\r\n\tat org.apache.spark.ml.tree.DecisionTreeRegressorParams$class.validateAndTransformSchema(treeParams.scala:315)\r\n\tat org.apache.spark.ml.regression.DecisionTreeRegressor.validateAndTransformSchema(DecisionTreeRegressor.scala:47)\r\n\tat org.apache.spark.ml.Predictor.transformSchema(Predictor.scala:144)\r\n\tat org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:100)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-67277fe06cca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#import decision tree and train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeaturesCol\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelCol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'winPlacePerc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdt_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdt_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[0mjava_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \"\"\"\n\u001b[0;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: 'Field \"features\" does not exist.\\nAvailable fields: assists, boosts, damageDealt, DBNOs, headshotKills, heals, killPlace, killPoints, kills, killStreaks, longestKill, matchDuration, matchType, maxPlace, numGroups, rankPoints, revives, rideDistance, roadKills, swimDistance, teamKills, vehicleDestroys, walkDistance, weaponsAcquired, winPoints, match_mean, match_median, totalPlayers, teamSize, killsNorm, damageDealtNorm, normMatchType, totalDistance, maxPossibleKills, itemsUsed, itemsPerDistance, killsPerDistance, damageDealtPerDistance, maxTeamKills, totalTeamKills, headshotKillRate, itemsUsedPerTeam, percKill, percTeamKills, meanTeamKillPlace'"
     ]
    }
   ],
   "source": [
    "\n",
    "#import decision tree and train the model\n",
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'winPlacePerc')\n",
    "dt_model = dt.fit(train_df)\n",
    "\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "dt_predictions.select(\"prediction\",\"winPlacePerc\",\"features\").show(5)\n",
    "\n",
    "#Calculating test score\n",
    "\n",
    "dt_evaluator = RegressionEvaluator(predictionCol=\"prediction\",\\\n",
    "labelCol=\"winPlacePerc\",metricName=\"r2\")\n",
    "\n",
    "print(\"R Squared (R2) on test data = %g\" % dt_evaluator.evaluate(dt_predictions))\n",
    "\n",
    "#Calculating RMSE\n",
    "dt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"winPlacePerc\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  }
 ]
}